# 第一章

### 1.4.2 设备驱动

操作系统作为硬件层的上层，它是对硬件的管理和抽象。对于操作系统上面运行库和应用程序来说，它们希望看到的是一个统一的硬件访问模式。作为应用程序的开发者，我们不希望在开发应用时候直接写硬件端口、处理硬件中断等事情。由于硬件之间千差万别，它们的操作方式和访问方式都有区别。比如我们希望在显示器上画一条直线，对于程序员来说，最好的方式是不管计算机使用什么显卡、显示器，我们都只要调用一个统一的lineTo函数，具体实现的方式由操作系统来完成。试想一下如果程序员需要关心具体的硬件，那么结果会是这样：对于A型号的显卡来说，需要往I/O端口0x1001写一个命令0x1111，然后从端口0x1002中读取一个4字节的显存地址，然后使用DDA逐个地在显存上画点，如果是B型号的显卡，可能完全是另一种方式。这简直就是灾难。不过在操作系统成熟之前，的确存在这样的情况，就是应用程序的程序员需要和硬件直接打交道。

当成熟的操作系统出现之后，硬件逐渐被抽象成了一系列概念。在UNIX中，硬件设备的访问形式跟访问普通文件形式一样：在Windows系统中，图形硬件被抽象成了GDI，声音和多媒体设备被抽象成了DirectX对象，等等。程序员逐渐从硬件细节中释放出来，可以更多地关注应用程序本身的开发。这些硬件细节都交给了操作系统，具体地讲是操作系统中的硬件驱动程序来完成。驱动程序可以看做是操作系统的一部分，它往往跟操作系统内核一起运行在特权级，但它又与操作系统意见有一定的独立性，使得驱动程序有比较好的灵活性。因为pc的硬件多如牛毛，操作系统开发者不可能为每一个硬件开发一个驱动程序，这些驱动程序的开发工作通常由硬件生产厂商完成。操作系统开发者为硬件生产厂商提供了一系列接口和框架，凡是按照这个接口和框架开发的驱动程序都可以在该操作系统上使用。让我们以一个读取文件为例子来看看操作系统和驱动程序在这个过程中扮演了什么样的角色。

提到文件的读取，那么不得不提到文件系统这个操作系统中最为重要的组成部分之一。文件踢动管理着磁盘中文件的存储方式，比如我们在linux系统下有一个文件/home/user/test.dat，长度为8000个字节。那么我们在创建这个文件的时候，Linux的ext3文件系统有可能将这个文件按照这样的方式存储在磁盘中：文件的前4096字节存储在磁盘的1000号扇区到1007号扇区，每个扇区512字节，8个扇区刚好4096字节：文件的第4097个字节到第8000字节共3904个字节，存储在磁盘的2000号扇区到2007号扇区，8个扇区也是4096字节，不过只存储了3904个有效字节，剩下的192个字节无效。如果把这个文件的存储方式看做一个链装的结构，它的结构如下：


```
这里我们先穿插一个关于硬盘结构的介绍，硬盘基本存储单位为扇区（sector），每个扇区一般为512字节。一个磁盘往往有很多个盘片，每个盘片分两面，每面分为若干个磁道，每个磁道划分为若干个扇区。比如一个硬盘有2个盘片，每个盘片有65536磁道，每个磁道分1024个扇区，那么硬盘的用量就是2 * 2 * 65536 * 1024 * 512 = 128GB。但是我们可以想象，每个盘面上同心圆的周长不一样，如果按照每个磁道都拥有相同数量的扇区，那么靠近盘面外围的密度比内圈要小，这样比较浪费空间。但是如果不同的磁道扇区数不同，计算起来就十分麻烦。为了屏蔽这些硬件细节，现代的硬盘普遍使用一种叫LBA（logical block address）的方式，即整个硬盘中所有的扇区从0号开始，一直到最后一个扇区，这个扇区编号叫做逻辑扇区编号。逻辑扇区编号抛弃了复杂的磁道、盘面之类的概念。当我们给出一个逻辑的扇区号时，磁盘的电子设备会将其转换成实际的盘面、磁道等这些位置。
```

文件系统保存了这些文件的存储结构，负责维护这些数据结构并且保证磁盘中的扇区能够有效地组织和利用。那么当我们在Linux操作系统中，要读取这个文件的前4096个字节时，我们会使用一个read的系统调用来实现。文件系统受到read请求之后，判断出文件的前4096个字节位于磁盘的1000号逻辑扇区到1007号扇区。然后文件系统就向硬盘驱动发出一个读取逻辑扇区1000号开始的8个扇区的请求，磁盘驱动程序受到这个请求以后就向硬盘发出硬件命令。向硬盘发送I/O命令的方式有很多种，其中最常见的一种能就是通过读写I/O端口寄存器来实现。在x86平台上，共有65536个硬件端口寄存器, 不同的硬件被分配到了不同的I/O端口地址。CPU提供了两条专门的指令“in”和“out”来实现对硬件端口的读和写。

对IDE接口来说，它有两个通道，分别为IDE0和IDE1，每个通道上可以连接两个设备，分别为Master和Slave，一个PC钟最多可以有4个IDE设备。假设我们的文件位于IDE0的master硬盘上，这也是正常情况下硬盘所在的位置。在PC中，IDE0通道的I/O端口地址是是0x1f0~0x1f7即0x376~0x377。通过读写这些地址就能与IDE硬盘进行通讯。这些端口的作用和操作方式十分复杂，我们以实现读取1000号逻辑扇区开始的8个扇区为例：

* 第0x1F3~0x1F6 4个字节的端口地址是用来写入LBA地址的，那么1000号逻辑扇区的LBA地址为0x000003e8，所以我们需要往0x1f3、0x1f4写入0x00,往0x1f5写入0x03，往0x1f6写入0xe8。

* 0x1f2这个地址用来写入命令所需要读写的扇区数。比如读取8个扇区即写入8.

* 0x1f7这个地址用来写入要执行的操作的命令吗，对于读取操作来说，命令字为0x20。
所以我们要执行的指令为：

out 0x1f3, 0x00

out 0x1f4, 0x00

out 0x1f5, 0x03

out 0x1f6, 0xe8

out 0x1f2, 0x08

out 0x1f7, 0x20

在硬盘收到这个命令以后，就会执行响应的操作，并且将数据读取到事先设置好的内存地址中（这个内存地址也是通过类似的命令方式设置的）。当然这里的例子中只是最简单的情况，时机情况比这个复杂得多，驱动程序要考虑硬件的状态、调度和分配各个请求以达到最高的性能等。

## 1.5 内存不够怎么办

上面一节我们提到了进程的概念，进程的总体目标是希望每个进程从逻辑上来看都可以独占计算机的资源。操作系统的多任务功能使得cpu能够在多个进程之间很好的共享，从进程的角度看好像是独占了cpu而不用考虑与其他进程分享cpu的事情。操作系统的I/O抽象模型也很好地实现了I/O设备的共享和抽象，那么唯一剩下的就是主存，也就是内存的分配问题了。

在早起的计算机中，程序直接运行在物理内存上，也就是说，程序在运行时所访问的都是物理地址。当然，如果一个计算机同事运行一个程序，那么只要程序要求的内存空间不要超过物理内存的大小，就不会有问题。但是事实上为了更有效地利用硬件资源，我么必须同事运行多个程序，正如前面的多道程序、分析系统和多任务中一样，当我们能够同时运行多个程序是，cpu的利用率将会比较高。那么很明显的一个问题是，如何将计算机上有限的物理内存分配给多个程序使用。

假设我们的计算机有128MB内存。程序A需要10MB,程序B需要100MB，程序C需要20MB。如果我们需要同时运行程序A和B，那么比较直接的做法是将内存的前10MB分配给程序A，10MB~110MB分配给B。这样就能实现A和B两个程序同时运行，但是这种简单的内存分配策略问题很多。

* 地址空间不隔离 左右程序都直接访问物理地址，程序所使用的内存空间不是互相隔离的。恶意的程序可以很容易改写其他程序的内存数据，以达到破坏的目的；有些非恶意的、但是有bug的程序可能不小心修改了其他程序的数据，就会使其他程序也崩溃，这对于需要安全稳定的计算机环境的用户来说是不可容忍的。用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他的任务。

* 内存使用效率低 由于没有有效的内存管理机制，通常需要一个程序执行时，监控程序就将整个程序装入内存然后开始执行。如果我们忽略需要执行程序c，那么那么这时的内存空间其实已经不够了，这时候我们可以用的一个办法是将其他程序的数据暂时写到磁盘里面，等到需要用到的时候再读回来。由于程序所需要的内存是连续的，那么这个例子里面，如果我们将程序A换出到磁盘所释放的内存空间是不够的，所以只能讲b换出到磁盘，然后将c读入到内存开始运行。可以看到整个过程中有大量的数据在换入换出，导致效率十分低下。

* 程序运行的地taolun程序每次需要装入运行时，我们需要给内存中分配一块足够大的空闲内存区域，这个空闲区域的位置是不确定的。这个程序编写造成了一定的麻烦，因为程序在编写时，它访问数据和命令指令跳转时的目标地址很多都是固定的，这涉及程序的重定位问题，我们在第2部分和第3部分还会详细讨论。

解决这几个问题的思路就是使用我们前文提到的法宝：增加中间层，即使用一种简介的地址访问方法。整个想法是这样的，我们把程序给出的地址看做是一种虚拟地址，然后通过某些映射方法，将这个虚拟地址转换成实际的物理地址。这样，只要我们能够妥善地控制这个虚拟地址到物理地址的映射过程，就可以保证任意一个程序所能访问的物理内存区域跟另外一个程序互相不重叠，以达到地址空间隔离的效果。

### 1.5.1 关于隔离

让我们回到程序的运行本质上来。用户程序在运行时不希望介入到这些复杂的存储器管理过程中，作为普通的程序，它需要的是一个简单的执行环境，有个单一的地址空间、有自己的CPU，好像整个程序占有整个计算机而不需要关心其他的程序（当然程序间通信的部分除外)，你可以把它想象成一个很大的数组，每个数组的元素是一个字节，而这个数组大小由地址空间的地址长度决定，比如32位的地址空间的大小为2^32字节，即4GB，地址空间有效的地址长度是0~4294967295，用十六进制表示就是0x00000000~0xFFFFFFF。地址空间分两种：虚拟地址空间和物理地址空间。物理地址空间实实在在存在，存在于计算机中，而且对于每一台计算机来说只有唯一的一个，你可以把物理空间想象成物理内存，比如你的计算机用的intel处理器，那么它是32位的机器，即计算机地址线有32条（实际上有36条地址线），那么物理空间就有4GB。但是你的计算机上只装了512MB的内存，那么其实物理地址的真正有效部分只有0x00000000~0x1FFFFFFF,其他部分都是无效的（实际上还有一些外部I/O设备映射到物理空间的，也是有效的。但是我们暂时无视其存在）。虚拟地址空间指虚拟的、人们想象出来的地址空间，其实它并不存在，每个进程都有自己独立的虚拟空间，而且每个进程只能访问自己的地址空间，这样就有效地做到了进程的隔离。

### 1.5.2 分段

最开始人们使用的是一种叫分段的方法，基本思路是把一段与程序所需要的内存空间大小的虚拟地址映射到某个地址空间。比如程序A需要10MB内存，那么我们假设有一个地址从0x00000000到0x00A00000的10MB大小的一个假象的空间，也就是虚拟空间，然后我们从实际的物理内存中分配一个相同大小的物理地址，假设是物理地址0x00100000开始到0x00B00000结束的一块空间。然后我们把这两块相同大小的地址空间一一映射，即虚拟空间中的每个字节相对应与物理空间的每个字节。这个映射过程由软件来设置，比如操作系统来设置这个映射函数，时机的地址转换由硬件完成。比如当程序A中访问地址0x00001000时，CPU会将这个地址转换成实际的物理地址0x00101000。那么比如程序A和程序B在运行时，它们的虚拟地址和物理空间映射关系可能如下：

分段的方法基本解决了上面提到的3个问题中的第一个和第三个，它们之间没有任何重叠，如果程序A访问虚拟哦空间的地址超出了0x00A00000这个范围，那么硬件就会判断这是一个非法访问，拒绝这个地址请求，并将这个请求报告给操作系统或监控程序，由它来决定如何处理。再者，对于每个程序来说，无论他们被分配到了物理地址的哪一个区域，对于程序来说都是透明的，他们不需要关心物理地址的变化，他们只需要按照从地址0x00000000到0x00A000000来编写程序、放置变量，所以程序不再需要重定位。

但是分段的这种方法还是没有解决我们的第二个问题，即内存使用效率的问题。分段对内存区域的映射还是按照程序为单位，如果内存不足，被还如换出到磁盘的都是整个程序，这样势必会造成大量的磁盘访问操作，从而严重影响速度，这种方法还是显得粗糙，粒度比较大。事实上，根据程序的局部性原理，当一个程序运行时，在某个时间段内，它只是频繁地使用到了一小部分数据，也就是说，程序很多数据其实在一段时间内都是不会被用到的。人们很自然地想到了更小粒度的内存分隔和映射方法，使得程序的局部性原理充分的利用，大大提高了内存的使用率。这种方法就是分页。

### 1.5.3 分页

分页的基本方法是把地址空间认为地等分成固定大小的页，每一页的大小由硬件决定或者硬件支持多种大小的页，由操作系统选择决定页的大小。比如Intel Pentium系列处理器支持4kb或4mb的页大小，那么操作系统可以选择每页大小为4kb，也可以选择每页大小为4mb，但是在同一时刻只能选择一种大小，所以对整个系统来说，页就是固定大小的。目前几乎所有的pc上的操作系统都使用4kb大小的页。我们使用的pc机是32位虚拟地址空间，也就是4gb，那么按4kb每页分的话，总共有1048476个页。物理空间也是同样的分法。

下面我们来看一个简单的例子，如图，每个虚拟空间有8页，每页大小为1kb，那么虚拟地址空间就是8kb。我们假设该计算机有13条地址线，即拥有2^13的物理寻址能力，那么理论上物理空间可以多打8kb。但是出于种种原因，购买内存的资金不足，只买得起6kb的内存，所以物理空间其实真正有效的只是前6kb。

那么，当我们把进程的虚拟地址空间按页分割，把常用的数据和代码页装载到内存中，把不常用的代码和数据保存在磁盘里，当需要用到的时候把它从磁盘里取出来即可。

如图中，我们假设有两个进程process1和process2，它们进程中的部分虚拟页面被映射到了物理页面，比如vp0、vp1和vp7映射到了pp0、pp2和pp3；而有部分页面却在磁盘中，比如vp2和vp3位于磁盘的dp0和dp1中；另外还有一些页面如vp4、vp5和vp6可能尚未被用到或访问到，它们暂时处于未使用的状态。这里，我们把虚拟空间的页就叫虚拟页，把物理内存的页叫做物理页，把磁盘中的页叫磁盘页。图中的线表示映射关系，我们可以看到虚拟空间有些页被映射到了同一个物理页，这样就可以实现内存共享。

图中process1的vp2和vp3不在内存中，但是当进程需要用到这两个页的时候，硬件会捕获到这个消息，这就是所谓的页错误（page fault），然后操作系统接管进程，负责将vp2和vp3从磁盘中读出来并装入内存，然后将内存中的这两个页与vp2和vp3建立映射关系。

## 1.6 众人拾柴火焰高

### 1.6.1 线程基础

现代软件系统中，除了进程之外，线程也是一个十分重要的概念。特别是随着cpu频率增长开始出现停滞，而开始向多核方向发展。多线程，作为实现软件并发执行的一个重要方法，也开始具有越来越重要的地位。我们将在这一节回顾相关的内容，包括线程的概念、线程的调度、线程安全、用户线程与内核线程之间的映射关系。虽然线程相关的概念与本书的内容并不是十分相关，但是我们相信深刻理解线程对于更加深入地理解装载、动态连接和运行库，特别是运行库与多线程相关部分的内容会有很大的帮助。

什么是线程

线程，有时被称为轻量级进程，是程序执行流的最小单元。一个标准的线程由线程ID、当前指令指针（PC)、寄存器集合和堆栈组成。通常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码段、数据段、堆等）及一些进程的资源（如打开文件好和信号）。一个经典的与线程与进程的关系如下图：

大多数软件应用中，线程的数量都不止一个。多个线程可以互不干扰地并发执行，并共享进程的全局变量和堆的数据。那么，多个线程与单线程的进程相比，又有哪些优势？

* 某个操作可能会陷入长时间等待，等待的线程会进入睡眠状态，无法继续执行。多线程执行可以有效利用等待的时间。

* 某个操作会消耗大量的时间，如果只有一个线程，程序和用户之间的交互会中断。多线程可以让一个线程负责交互，另一个线程负责计算。

*程序逻辑本很就要求并发操作，例如一个多端下载软件。

* 多cpu或多核计算机，本身具备同事执行多个线程的能力，因此单线程程序无法全面地发挥计算机的全部能力。

* 相对于多线程应用，多线程在数据共享方面效率要高很多。

线程的访问权限

线程的访问非常自由，它可以访问进程内存里的所有数据，甚至包括其他线程的堆栈，但实际运用中线程也拥有自己的私有存储空间，

* 栈

* 线程局部存储（Thread Local Storage， TLS）。线程局部存储是某些操作系统为线程单独提供的私有空间，但通常只具有有限的容量。

* 寄存器，寄存器是执行流的基本数据，因此为线程私有。

从c程序员的角度来看，数据在线程之间是否私有如下表:

线程调度与优先级

不论是在多处理器的计算机上还是在单处理器的计算机上，线程总是“并发”执行的。当线程数量小于等于处理器数量时线程的并发是真正的并发，不同的线程运行在不同的处理器上，彼此之间互不相干。但对于线程数量大于处理器数量的情况，线程的并发会受到一些阻碍，因为此时至少有一个处理器会运行多个线程。

在单处理器对应多线程的情况下，并发是一种模拟出来的状态。操作系统会让这些多线程程序轮流执行，每次仅执行一小段时间，这样每个线程就“看起来”在同时执行。这样的一个不断在处理器上切换不同的线程的行为称之为线程调度。在线程调度中，线程通常拥有至少三种状态，分别是：

* 运行

* 就绪

* 等待

处于运行中线程拥有一段可以执行的时间，这段时间称为时间片，当时间片用尽的时候，该进程就将进入就绪状态。如果在时间片用尽之前进程就开始等待某事件，那么它将进入等待状态。每当一个线程离开运行状态时，调度系统会选择一个其他的就绪线程继续执行。在一个处于等待状态的线程所等待的事件发生之后，该线程将进入就绪状态。

线程调度自多任务系统问世以来就不断地被提出不同的方案和算法。，现在主流的调度方法尽管各部相同，但是都带有优先级调度和轮转法的痕迹。所谓轮转法，即是之前提到的让哥哥线程轮流执行一小段时间的方法。这决定了线程之间交错执行的特点。而优先级调度决定了线程按照什么顺序轮流执行。在具有优先级调度的系统中，线程都拥有各自的线程优先级。具有高优先级的线程会更早的执行，而低优先级的线程常常要等待到系统中已经没有高优先级的可执行线程存在时才能执行。在windows中，可以通过使用setThreadPriority来设置线程的优先级，而linux下与线程相关的操作可以通过pthread库来实现。

在windows和linux中，线程的优先级不仅可以由用户手动设置，系统还会根据不同的线程的表现自动调整优先级，以使得调度更有效率。例如通常情况下，频繁地进入等待状态的线程比频繁进行大量计算、以至于每次都要把时间全部用尽的线程要受欢迎得多。其实道理很简单，频繁等待的线程通常占用很少时间，CPU也喜欢先捏软柿子。我们一般把频繁等待的线程称之为io密集型线程，而把很少等待的线程称为CPU密集型线程。io密集型线程总是比cpu密集型线程更容易得到优先级的提升。

在优先级调度下，存在一种饿死的现象，一个线程被饿死，是说它的优先级较低，在他执行之前，总是有优先级较高的线程试图执行，因此这个低优先级的线程始终无法执行。当一个cpu密集型的线程获得较高优先级时，许多优先级进程都有可能饿死。而一个高优先级的io密集型线程由于大部分时间都处于等待状态，因此相对不容易造成其他线程饿死。为了避免饿死现象，调度系统常常会逐步提升那些等待了过长时间的得不到执行的线程的优先级。在这样的手段下，一个线程只要等待足够长的时间，其优先级一定会提高到足够让它执行的程度。

我们总结一下，在优先级调度的环境下，线程的优先级改变一般有三种方示：

* 用户指定优先级

* 根据进入等待状态的频繁程度提升或降低优先级

* 长时间得不到执行而被提升优先级

可抢占线程和不可抢占线程

我们之前讨论的线程调度有一个特点，那就是线程在用时间片后会被强制剥夺继续执行的权利，而进入就绪状态，这个过程叫做抢占，即之后执行的别的线程抢占了当前线程。在早起的一些系统里，线程是不可抢占的。线程必须手动发出一个放弃执行的命令，才能让其他的线程得到执行。在这样的调度模型下，线程必须主动进入就绪状态，而不是靠时间片用尽来被强制进入。不可抢占线程中，线程主动放弃执行无非两种情况。

* 当线程试图等待某时间时。

* 线程主动放弃时间片。

因此在不可抢占线程执行的手，有一个显著的特点，那就是线程调度的时机是确定的，线程调度只会发生在线程主动放弃执行或者线程等待某事件的时候，这样可以避免一些因为抢占式线程里调度时机不确定而产生的问题。但即使如此，非抢占线程在今日已经十分少见了。

linux的多线程

windows对线程和进程的实现如同教科书一般标准，windows内核有明确的线程和进程概念。在windows api中，可以使用明确的api：createprocess和createthread来创建进程和线程，并且有一系列api来操纵它们。但对于linux来说，线程并不是一个通用概念。

linux对线程的支持颇为频发，在linux内核中并不存在真正意义上的线程概念。linux将所有的执行实体称为任务，每一个任务概念上都累死一个单线程的进程，具有内存空间、执行实体、文件资源等。不过linux下不同的任务之间可以选择共享内存空间，因而在时机意义上，共享了同一个内存的多个任务构成了一个进程，这些任务也就成了这个仅成立的线程。在linux下，用一下方法可以创建一个新的任务：

* for

* exec

* clone


pid_t pid;

if(pid=fork()){
   ...
}

在fork函数调用之后，新的任务将启动并和本任务一起从fork函数返回。但不同的是本任务的fork将返回新任务pid，而新任务的fork将返回0。

fork函数产生一个和当前进程完全一样的新进程，并和当前进城一样从fork函数里返回。
产生新任务的速度非常快，因为fork病不复制原任务的内存空间。而是和原任务一起共享一个写时复制的内存空间。所谓写时复制，指的是两个任务可以同时自由地读取内存，但任意一个任务试图对内存进行修改时，内存就会复制一份提供给修改方单独使用，以免影响其他的任务使用。

fork只能够产生本任务的镜像，因此需要使用exec配合才能启动别的新任务。exec可以用新的可执行影像替换当前的可执行影像，因此在fork产生了一个新任务之后，新任务可以调用exec来执行新的可执行文件。fork和exec通常用于产生新任务，而如果要产生新线程，则可以使用clone。clone函数的原型如下：

int clone(int (*fn)(void*), void *child_stack, int flags, void *arg);

使用clone可以产生一个新的任务，从指定的位置开始执行，并且共享当前进程的内存空间和文件等。如此就可以在时机效果生产生一个线程。
‘
### 1.6.2 线程安全

多线程程序处于一个多变的环境当中，可访问的全局变量和堆数据随时都可能被其他的线程改变。因此多线程程序在并发是数据的一致性非常重要。

竞争与原子操作

多线程同事访问一个共享数据时，可能造成很恶劣的后果。下面是一个著名的例子，假设由两个线程分别要执行如表所示的c代码。


-----|-----
i=1; |--i;
i++; |

在许多体系结构上，++i的实现方式如下：

1）读取i到某个寄存器x。

2） x++

3） 将x的内存存储回i

由于线程1和线程2并发执行，因此两个线程的执行顺序很可能如下（注意，寄存器x的内容不同的线程中是不一样的，这里用x1和x2分别表示线程1和线程2中的x，如下：


从程序逻辑来看，两个线程都执行完毕后，i的值应该为一，但从之前的执行顺序可以看到，i得到的值是0.实际上这两个线程如果同时执行的话，i的结果有可能是0或1或2.可见两个程序同时读写同一个共享数据会导致意想不到的后果。

很明显，自增操作在多线程环境下会出现错误是因为这个操作被编译为汇编代码之后不止一条指令，因此在执行的时候可能执行了一般就被调度系统打断，去执行别的代码。我们把单指令的操作称为原子的，因为无论如何，单指令的操作都不会被打断。为了避免出错，很多体系结构都提供了一些常用的原子指令，例如i386就有一条inc指令可以直接增加一个内存单元值，可以避免上述错误。在windows里有一套api专门进行一些原子操作，这些api称为interlocked api。

* interlockedExchange   原子地交换两个值

* interlockedDecrement  

* interlockedIncrement

* interlockedXor

使用这些函数时，windows将保证是原子操作的，因此可以不用担心出现问题。遗憾的是，尽管原子操作指令非常方便，但是它们仅使用于比较简单特定的场合。在复杂的场合下，比如我们需要更加通用的手段：锁。

同步与锁

为了避免线程同时读写同一个数据而产生不可预料的后果，我们需要将各自线程对同一个数据的访问同步。所谓同步，即 是指在一个线程访问数据未结束的时候，其他线程不得对同一数据进行访问。如此，对数据的访问被原子化了。

同步的最常见方法是使用所。锁是一种非强制机制，每个线程在访问数据或资源之前首先试图获取所，并在访问结束之后释放所。在锁已经被占用的时候获取锁时，线程会等待，知道锁重新可用。

二元信号量是最简单的一种锁，它只有两种状态，占用和非占用。它适合只能被唯一一个线程独占访问的资源。当二元信号量置为占用状态，伺候其他的所有试图获取该二元信号量的线程会等待，直到该锁被释放。

对于允许多个线程并发访问的资源，多元信号量简称信号量，它是一个很好的选择。一个初始值为n的信号量允许n个线程允许并发访问。线程访问资源的时候首先获取信号量，进行如下操作。

* 将信号量减一

* 如果信号量的值小于0，则进入等待状态，否则继续执行。访问完资源之后，线程释放信号量，进行如下操作：

* 将信号量加以

* 如果信号量值小于1，唤醒一个等待中的线程

互斥量和二元信号量很类似，资源仅同时允许一个线程访问，但和信号量不同的是，信号量在整个系统可以被任意线程获取并释放，也就是说，同一个信号量可以被系统中的一个线程获取之后由另一个线程释放。而互斥量要求哪个线程获取了信号量，哪个线程就要负责释放这个所，其他线程越俎代庖释放互斥量是无效的。

临界区是比互斥量更加严格的同步手段，在术语中，把临界区的锁的获取称为进入临界区，而把锁释放称为离开临界区。临界区和互斥量与信号量的区别在于，互斥量和信号量在系统的任何进程都是可见的，也就是说，一个进程创建了一个互斥量和信号量，另一个进程试图获取该所是合法的。然而，临界区的作用范围仅限于本进程，其他的线程无法获取该锁。除此之外，性质相同。

读写锁致力于一种更加特定的场合的同步。对于一段数据，多个线程同时读取总是没问题的，但是假设操作都不是原子型，只要有任何一个线程试图对这个数据进行修改，就必须使用同步手段来避免出错。如果我们使用上述信号量、互斥量和临界区的任意一种来进行同步，尽管可以保证避免出错，但是对于读取频繁，而仅仅偶尔写入的情况，会显得非常抵消。读写多可以避免这个问题。对于同一个所，读写锁有两种获取方式，共享的和独占的。当锁处于自由的状态时，试图以任何一种方式获取锁都能成功，并将锁至于对应的状态。如果锁处于共享状态，其他线程以共享的方式获取仍会成功，此时这个锁分配给了多个线程。然而，如果其他线程以独占的方式获取已经处于共享状态的锁，那么它必须等待锁被所有的线程释放。相应地，处于独占状态的锁将组织任何其他线程获取该锁，不论它们试图以哪种方式获取。读写所的行为可以总结如下：

条件变量作为一种同步手段，作用类似于一个栅栏。对于条件变量，线程可以有两种操作，首先线程可以等待条件变量，一个条件变量可以被多个线程等待。其次，线程可以唤醒条件变量，此时某个或所有等待次条件变量的线程都会被唤醒并继续执行。也就是说，使用条件变量可以让多个线程一起等待某个时间的发生，当时间发生时，条件变量被唤醒，所有的线程可以一起恢复执行。

可重入（reentrant）与线程安全

一个函数被重入，表示这个函数没有被执行完成，由于外部因素或内部调用，又一次进入该函数执行。一个函数要被重入，只有两种情况：

1） 多个线程同时执行这个函数

2） 安徽省农户自身调用自身

一个函数被称为可重入的，表明该函数被重入之后不会产生任何不良后果。

一个函数要称为可重入的，必须具有如下特点：

* 不使用任何静态或全局的非const变量

* 不反悔任何静态或全局的非const变量的指针

* 仅依赖于调用发提供的参数

* 不依赖任何单个资源的锁

* 不调用任何不可重入的函数

可重入是并发安全的强力保障，一个可重入的函数可以在多线程下使用

过度优化

线程安全是一个非常烫手的山芋，因为即使合理地使用了锁，也不一定能保证线程安全，这是源于落后的编译技术已经无法满足日益增长的并发需求。很多看似无措的代码在优化和并发面前又产生了麻烦。最简单的例子，让我们看看如下代码：

x = 0

Thread1    Thread2
lock()     lock()
x++;       x++;
unlock()   unlock()


由于有lock和unlock保护，x++的行为不会被并发破坏，那么x的值似乎必然是2了。如果编译器为了调高x的访问速度，把x放到了某个寄存器里，那么我们知道不同线程的寄存器是各自独立的，因此如果thread1先获得锁，则程序的执行可能会呈现如下情况：

...


另一个颇为著名的与换序有关的问题来自于singleton模式的double-check。一段经典的double-check的singleton代码是这样的：

volatile T*pInst = 0;
T*GetInstance()
{

if (pInst == NULL)
{
	lock();
	if (pInst == NULL)
		pInst = new T;
	unlock();
}
return pInst;
}

抛开逻辑，这样的代码乍看没有什么问题，当函数返回时，pInst总是指向一个有效的对象。而lock和unlock防止了多线程竞争导致的麻烦。双重的if在这里有妙用，可以让lock的调用开销降低到最小。

但是实际上这样的代码有问题。问题的来源仍然是cpu的乱序执行。c++里的new其实包含了两个步骤：

1)分配内存

2）调用构造函数

所以pInst = new T包含了三个步骤：

1） 分配内存

2） 在内存的位置上调用构造函数

3） 将内存的地址赋值给pInst


